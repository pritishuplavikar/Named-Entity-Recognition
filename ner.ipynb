{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960M (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/home/pritish/.local/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/home/pritish/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import TimeDistributedDense, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from keras import backend as K\n",
    "\n",
    "raw = open('wikigold.conll.txt', 'r').readlines()\n",
    "\n",
    "all_x = []\n",
    "point = []\n",
    "for line in raw:\n",
    "    stripped_line = line.strip().split(' ')\n",
    "    point.append(stripped_line)\n",
    "    if line == '\\n':\n",
    "        all_x.append(point[:-1])\n",
    "        point = []\n",
    "all_x = all_x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length range:  144 1\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(x) for x in all_x]\n",
    "print ('Input sequence length range: ', max(lengths), min(lengths))\n",
    "\n",
    "short_x = [x for x in all_x if len(x) < 64]\n",
    "\n",
    "X = [[c[0] for c in x] for x in short_x]\n",
    "y = [[c[1] for c in y] for y in short_x]\n",
    "\n",
    "all_text = [c for x in X for c in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8285 5\n",
      "Maximum sequence length: 63\n",
      "{'I-PER': 3, 'I-ORG': 1, 'I-LOC': 4, 'I-MISC': 5, 'O': 2}\n"
     ]
    }
   ],
   "source": [
    "words = list(set(all_text))\n",
    "word2ind = {word: index for index, word in enumerate(words)}\n",
    "ind2word = {index: word for index, word in enumerate(words)}\n",
    "labels = list(set([c for x in y for c in x]))\n",
    "label2ind = {label: (index + 1) for index, label in enumerate(labels)}\n",
    "ind2label = {(index + 1): label for index, label in enumerate(labels)}\n",
    "print ('Vocabulary size:', len(word2ind), len(label2ind))\n",
    "\n",
    "maxlen = max([len(x) for x in X])\n",
    "print ('Maximum sequence length:', maxlen)\n",
    "print(label2ind)\n",
    "\n",
    "def encode(x, n):\n",
    "    result = np.zeros(n)\n",
    "    result[x] = 1\n",
    "    return result\n",
    "\n",
    "X_enc = [[word2ind[c] for c in x] for x in X]\n",
    "max_label = max(label2ind.values()) + 1\n",
    "y_enc = [[0] * (maxlen - len(ey)) + [label2ind[c] for c in ey] for ey in y]\n",
    "y_enc = [[encode(c, max_label) for c in ey] for ey in y_enc]\n",
    "\n",
    "X_enc = pad_sequences(X_enc, maxlen=maxlen)\n",
    "y_enc = pad_sequences(y_enc, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing tensor shapes: (1440, 63) (352, 63) (1440, 63, 6) (352, 63, 6)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 63, 128)       1060480     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/layers/core.py:1112: UserWarning: TimeDistributedDense is deprecated, please use TimeDistributed(Dense(...)) instead.\n",
      "  warnings.warn('TimeDistributedDense is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_1 (LSTM)                    (None, 63, 32)        20608       embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "timedistributeddense_1 (TimeDistr(None, 63, 6)         198         lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 63, 6)         0           timedistributeddense_1[0][0]     \n",
      "====================================================================================================\n",
      "Total params: 1081286\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1440 samples, validate on 352 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 1s - loss: 1.1916 - val_loss: 0.7767\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.7023 - val_loss: 0.6362\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.5650 - val_loss: 0.5199\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.4269 - val_loss: 0.4352\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.3321 - val_loss: 0.3951\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.2701 - val_loss: 0.3726\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.2175 - val_loss: 0.3548\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.1765 - val_loss: 0.3419\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.1410 - val_loss: 0.3408\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 1s - loss: 0.1106 - val_loss: 0.3303\n",
      "320/352 [==========================>...] - ETA: 0sRaw test score: 0.330337164077\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=11*32, train_size=45*32, random_state=42)\n",
    "print ('Training and testing tensor shapes:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "max_features = len(word2ind)\n",
    "embedding_size = 128\n",
    "hidden_size = 32\n",
    "out_size = len(label2ind) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen, mask_zero=True))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))  \n",
    "model.add(TimeDistributedDense(out_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "batch_size = 32\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Raw test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s     \n",
      "Training accuracy: 0.98590504451\n",
      "Training confusion matrix:\n",
      "[[ 1465    58     0    10     9]\n",
      " [   24 24708     0     9    11]\n",
      " [   11    17  1172    20     6]\n",
      " [   25    24    10  1055     2]\n",
      " [   21   138    12    11   838]]\n",
      "352/352 [==============================] - 0s     \n",
      "Testing accuracy: 0.899255247123\n",
      "Testing confusion matrix:\n",
      "[[ 205  103    8   14   27]\n",
      " [  85 6068   15    9   27]\n",
      " [  35   79  150    8   11]\n",
      " [  52   67    7  132   10]\n",
      " [  29  144    6    8   86]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.50492611,  0.9391735 ,  0.80645161,  0.77192982,  0.53416149]),\n",
       " array([ 0.57422969,  0.97807866,  0.53003534,  0.49253731,  0.31501832]),\n",
       " array([ 0.53735256,  0.95823135,  0.63965885,  0.60136674,  0.39631336]),\n",
       " array([ 357, 6204,  283,  268,  273]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(yh, pr):\n",
    "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
    "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
    "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
    "    fyh = [c for row in yh for c in row]\n",
    "    fpr = [c for row in ypr for c in row]\n",
    "    return fyh, fpr\n",
    "\n",
    "pr = model.predict_classes(X_train)\n",
    "yh = y_train.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print ('Training accuracy:', accuracy_score(fyh, fpr))\n",
    "print ('Training confusion matrix:')\n",
    "print (confusion_matrix(fyh, fpr))\n",
    "precision_recall_fscore_support(fyh, fpr)\n",
    "\n",
    "pr = model.predict_classes(X_test)\n",
    "yh = y_test.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print ('Testing accuracy:', accuracy_score(fyh, fpr))\n",
    "print ('Testing confusion matrix:')\n",
    "print (confusion_matrix(fyh, fpr))\n",
    "precision_recall_fscore_support(fyh, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'was', 'a', 'member', 'of', 'US', 'Army']\n",
      "['I-PER', 'O', 'O', 'O', 'O', 'I-LOC', 'I-ORG']\n"
     ]
    }
   ],
   "source": [
    "string = \"John was a member of US Army\"\n",
    "wordlist = string.split(' ')\n",
    "ip = []\n",
    "for x in wordlist:\n",
    "    ip.append(word2ind[x])\n",
    "i=maxlen-len(ip)\n",
    "temp=[0]*i\n",
    "ip=temp+ip\n",
    "op = K.function([model.layers[0].input], model.layers[3].output)\n",
    "out = op([[ip]])\n",
    "temp = []\n",
    "while i<maxlen:\n",
    "    for j in label2ind:\n",
    "        if label2ind[j]==out[0][i].tolist().index(max(out[0][i])):\n",
    "            temp.append(j)\n",
    "    i=i+1\n",
    "print(wordlist)\n",
    "print(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
